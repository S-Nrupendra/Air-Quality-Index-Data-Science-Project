{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b671c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6b8d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station day shape: (108035, 16)\n",
      "Stations shape: (230, 5)\n"
     ]
    }
   ],
   "source": [
    "station_day = pd.read_csv('station_day.csv\\station_day.csv')\n",
    "stations = pd.read_csv('station_day.csv\\stations.csv')\n",
    "\n",
    "print(\"Station day shape:\", station_day.shape)\n",
    "print(\"Stations shape:\", stations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77709dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns: {'StationId'}\n",
      "Merged shape: (108035, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Common columns:\", set(station_day.columns).intersection(stations.columns))\n",
    "\n",
    "if 'station_id' in station_day.columns and 'station_id' in stations.columns:\n",
    "    data = station_day.merge(stations, on='station_id', how='left')\n",
    "else:\n",
    "    data = station_day.copy()\n",
    "\n",
    "print(\"Merged shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6831cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['StationId', 'StationName', 'state', 'city', 'location', 'Date', 'date']\n",
    "drop_cols = [c for c in drop_cols if c in data.columns]\n",
    "data = data.drop(columns=drop_cols, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c07cfa5",
   "metadata": {},
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85c62c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing value percentages:\n",
      " Xylene        0.788050\n",
      "NH3           0.445272\n",
      "PM10          0.395298\n",
      "Toluene       0.358236\n",
      "Benzene       0.291156\n",
      "O3            0.236664\n",
      "SO2           0.233295\n",
      "PM2.5         0.200167\n",
      "AQI_Bucket    0.194474\n",
      "AQI           0.194474\n",
      "NO            0.158338\n",
      "NO2           0.153163\n",
      "NOx           0.143472\n",
      "CO            0.120313\n",
      "dtype: float64\n",
      "\n",
      "Columns with >70% missing: ['Xylene']\n"
     ]
    }
   ],
   "source": [
    "missing_percent = data.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nMissing value percentages:\\n\", missing_percent)\n",
    "\n",
    "cols_high_missing = missing_percent[missing_percent > 0.7].index.tolist()\n",
    "print(\"\\nColumns with >70% missing:\", cols_high_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6112884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two datasets:\n",
    "#   1. one including xylene (after imputation)\n",
    "#   2. one excluding xylene\n",
    "\n",
    "data_with_xylene = data.copy()\n",
    "data_without_xylene = data.drop(columns=cols_high_missing, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79bce415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric columns\n",
    "\n",
    "numeric_cols_with = data_with_xylene.select_dtypes(include=[np.number]).columns\n",
    "numeric_cols_without = data_without_xylene.select_dtypes(include=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b776b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputer for median filling\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "data_with_xylene[numeric_cols_with] = imputer.fit_transform(data_with_xylene[numeric_cols_with])\n",
    "data_without_xylene[numeric_cols_without] = imputer.fit_transform(data_without_xylene[numeric_cols_without])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97f3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle categorical columns if any i.e., one-hot encoding\n",
    "cat_cols = data_with_xylene.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    data_with_xylene = pd.get_dummies(data_with_xylene, columns=cat_cols, drop_first=True)\n",
    "    data_without_xylene = pd.get_dummies(data_without_xylene, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd2e7d",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3fd3a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_with = data_with_xylene.drop(columns=['AQI', 'AQI_Bucket'], errors='ignore')\n",
    "y_with = data_with_xylene['AQI']\n",
    "\n",
    "X_without = data_without_xylene.drop(columns=['AQI', 'AQI_Bucket'], errors='ignore')\n",
    "y_without = data_without_xylene['AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9971cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler_with = StandardScaler()\n",
    "scaler_without = StandardScaler()\n",
    "\n",
    "X_with_scaled = pd.DataFrame(\n",
    "    scaler_with.fit_transform(X_with),\n",
    "    columns=X_with.columns\n",
    ")\n",
    "\n",
    "X_without_scaled = pd.DataFrame(\n",
    "    scaler_without.fit_transform(X_without),\n",
    "    columns=X_without.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9511811d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Data cleaning & feature engineering done!\n",
      "With Xylene: (108035, 17)\n",
      "Without Xylene: (108035, 16)\n",
      "Saved: cleaned_with_xylene.csv & cleaned_without_xylene.csv\n"
     ]
    }
   ],
   "source": [
    "# Final Cleaned Outputs\n",
    "print(\"\\n✅ Data cleaning & feature engineering done!\")\n",
    "print(\"With Xylene:\", X_with_scaled.shape)\n",
    "print(\"Without Xylene:\", X_without_scaled.shape)\n",
    "\n",
    "X_with_scaled['AQI'] = y_with.values\n",
    "X_without_scaled['AQI'] = y_without.values\n",
    "\n",
    "X_with_scaled.to_csv(\"cleaned_with_xylene.csv\", index=False)\n",
    "X_without_scaled.to_csv(\"cleaned_without_xylene.csv\", index=False)\n",
    "\n",
    "print(\"Saved: cleaned_with_xylene.csv & cleaned_without_xylene.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795487d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
